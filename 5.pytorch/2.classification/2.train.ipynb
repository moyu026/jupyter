{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.vision_transformer import vit_b_16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    \"val\": transforms.Compose([transforms.Resize(224),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "# data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
    "image_path = r\"F:\\PythonWork\\0.other\\0.study\\detect\\deep-learning-for-image-processing-master\\data_set\\flower_data\"  # flower data set path\n",
    "assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                     transform=data_transform[\"train\"])\n",
    "train_num = len(train_dataset)\n",
    "\n",
    "# {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}\n",
    "flower_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "# write dict into json file\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)\n",
    "\n",
    "batch_size = 16\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=nw)\n",
    "\n",
    "validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                        transform=data_transform[\"val\"])\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=nw)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "\n",
    "# net = vit_b_16(weights=\"IMAGENET1K_SWAG_E2E_V1\")\n",
    "net = vit_b_16()\n",
    "# load pretrain weights\n",
    "# download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "model_weight_path = \"vit_b_16-c867db91.pth\"\n",
    "assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
    "# for param in net.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# change fc layer structure\n",
    "in_channel = net.heads.head.in_features\n",
    "net.heads.head = nn.Linear(in_channel, 5)\n",
    "net.to(device)\n",
    "\n",
    "# define loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in net.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "epochs = 200\n",
    "best_acc = 0.0\n",
    "save_path = './resNet34.pth'\n",
    "train_steps = len(train_loader)\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(images.to(device))\n",
    "        loss = loss_function(logits, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                 epochs,\n",
    "                                                                 loss)\n",
    "\n",
    "    # validate\n",
    "    net.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = net(val_images.to(device))\n",
    "            # loss = loss_function(outputs, test_labels)\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "            val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,\n",
    "                                                       epochs)\n",
    "\n",
    "    val_accurate = acc / val_num\n",
    "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "          (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
