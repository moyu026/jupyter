{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from model import resnet34\n",
    "# 导入tensorboard库\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device.\".format(device))\n",
    "\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "image_path = os.path.join(data_root, \"data_set\", \"flower_data\")\n",
    "assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                     transform=data_transform[\"train\"])\n",
    "train_num = len(train_dataset)\n",
    "\n",
    "flower_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)\n",
    "\n",
    "batch_size = 16\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])\n",
    "print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=nw)\n",
    "\n",
    "validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                        transform=data_transform[\"val\"])\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=nw)\n",
    "\n",
    "print(\"Using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "net = resnet34()\n",
    "model_weight_path = \"./resnet34-pre.pth\"\n",
    "assert os.path.exists(model_weight_path), \"File {} does not exist.\".format(model_weight_path)\n",
    "net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
    "\n",
    "in_channel = net.fc.in_features\n",
    "net.fc = nn.Linear(in_channel, 5)\n",
    "net.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "params = [p for p in net.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "epochs = 30\n",
    "best_acc = 0.0\n",
    "save_path = './resNet34.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ae97f",
   "metadata": {},
   "source": [
    "### 创建tensorboard的日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19dd1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SummaryWriter for logging\n",
    "log_dir = os.path.join('logs', datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "writer = SummaryWriter(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace68e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "\n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(images.to(device))\n",
    "        loss = loss_function(logits, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        writer.add_scalar('Train/Loss', loss, epoch) # 记录loss到tensorboard中\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"Train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "\n",
    "    net.eval()\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "            val_bar.desc = \"Validation epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "\n",
    "    val_accurate = acc / val_num\n",
    "    print('[Epoch %d] Train_loss: %.3f  Val_accuracy: %.3f' %\n",
    "          (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "    \n",
    "    writer.add_scalar('Validation/Accuracy', val_accurate, epoch) # 记录val_accurate到tensorboard中\n",
    "\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "\n",
    "# Close the SummaryWriter\n",
    "writer.close()\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
