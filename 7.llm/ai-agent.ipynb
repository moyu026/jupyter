{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942b4fca-5539-4491-8bd0-61090bb0991c",
   "metadata": {},
   "source": [
    "### 使用AutoGen + Ollama 创建智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072eeb7-2d24-4bcc-861b-da755ba73787",
   "metadata": {},
   "source": [
    "- 1.安装ollama:`ollama.ai`\n",
    "- 2.使用ollama下载要使用的模型：\n",
    "  - `ollama run mistral`\n",
    "  - `ollama run codellama`\n",
    "- 3.创建conda环境python>3.10\n",
    "- 4.安装autogen:`pip install pyautogen`\n",
    "- 5.安装litellama:`pip install litellm`\n",
    "- 6.安装一些依赖包:\n",
    "    - `pip install litellm[proxy]`\n",
    "- 7.使用litellm加载ollama中下载的模型(**在代码中把http://0.0.0.0:4000改为http://127.0.0.1:4000，关闭vpn**):\n",
    "   - `litellm --model ollama/mistral`\n",
    "   - `litellm --model ollama/codellama`\n",
    "     \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268cbb09-d331-4534-a8ff-07f431573d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76fecab-82c5-4474-ac1b-579ffcb91796",
   "metadata": {},
   "source": [
    "##### 配置大型语言模型（LLMs）的服务地址、API密钥及模型名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c68d8f-625c-4b79-9c51-10780bc6f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_mistral = [\n",
    "    {\n",
    "        'base_url': 'http://127.0.0.1:4000',\n",
    "        'api_key': 'NULL',\n",
    "        'model': \"mistral\"\n",
    "    }\n",
    "]\n",
    "\n",
    "config_list_qwen = [\n",
    "    {\n",
    "        'base_url': 'http://127.0.0.1:45315',\n",
    "        'api_key': 'NULL',\n",
    "        'model': \"qwen\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87790df8-689e-4e19-bcd2-a26e8b56640e",
   "metadata": {},
   "source": [
    "##### 创建LLM配置对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b32c1c-71a5-401c-b7e3-81d60a50b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_mistral = {\n",
    "    'config_list': config_list_mistral,\n",
    "}\n",
    "\n",
    "llm_config_qwen = {\n",
    "    'config_list': config_list_qwen,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b86fc-5371-422d-9a09-a3d6408db329",
   "metadata": {},
   "source": [
    "##### 初始化三个智能体：\n",
    "- assistant：使用名为“mistral”的LLM模型的助理型智能体。\n",
    "- coder：使用名为“codellama”的LLM模型的编程专家型智能体。\n",
    "- user_proxy：代表用户的人工智能代理，可以接收用户的输入并在满足条件时终止对话。设置了参数如最大连续自动回复次数、终止消息判断函数（当消息内容以'TERMINATE'结尾时终止对话）、禁用了代码执行功能（或者指定了工作目录，这里注释掉了），并使用“mistral”模型进行文本生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bfca1b-755a-4803-87e4-4e706524535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = autogen.AssistantAgent(\n",
    "    name='Assistant',\n",
    "    llm_config=llm_config_mistral,\n",
    ")\n",
    "\n",
    "poet = autogen.AssistantAgent(\n",
    "    name='poet',\n",
    "    llm_config=llm_config_qwen,\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name='user_proxy',\n",
    "    human_input_mode='TERMINATE',\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get('content', '').rstrip().endswith('TERMINATE'),\n",
    "    # code_execution_config={'woek_dir':'web'},\n",
    "    code_execution_config=False,\n",
    "    llm_config=llm_config_mistral,\n",
    "    system_message=\"\"\"Reply Terminate if the task has been solved at full satisfaction.\n",
    "    Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c8deb-c602-4cd1-ab5d-cad4d3808189",
   "metadata": {},
   "source": [
    "##### 定义一个初始任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78ff01c-16fc-410e-8a6f-c6691fc164a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = '写一首关于人工智能的七言绝句'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512ba8c-08d5-4ff9-afa2-bab812854b80",
   "metadata": {},
   "source": [
    "##### 创建一个群聊实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0e511d-0157-4617-b3cb-20649905dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用上述定义的三个智能体创建一个群聊，初始化消息列表为空，并设置了最多可进行12轮对话。\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, poet, assistant], messages=[], max_round=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfadd71-2c3d-483b-bcd5-737b53d3224f",
   "metadata": {},
   "source": [
    "##### 创建群聊管理器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f2237c-d634-485e-9f5f-3e5c8ed2dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 群聊管理器用于协调和管理整个对话过程，这里传入了之前创建的群聊实例和其中一个LLM配置。\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a7e45-5c7e-44dc-bd47-ed646ce75dbb",
   "metadata": {},
   "source": [
    "##### 开始对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e617c-f915-46c4-8848-79278f60252d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "写一首关于人工智能的七言绝句\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(manager, message=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d31ab-6645-4637-ae8a-a074bb0c7d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
